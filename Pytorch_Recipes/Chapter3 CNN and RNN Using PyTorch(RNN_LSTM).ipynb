{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3633a317",
   "metadata": {},
   "source": [
    "# CHAPTER 3\n",
    "CNN and RNN Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842c7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28\n",
    "INPUT_SIZE = 28\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d72ef",
   "metadata": {},
   "source": [
    "## Recipe 3-8. Implementing aÂ Recurrent Neural Network (RNN)\n",
    "The recurrent neural network is considered as a memory net work. It takes a sequence of vectors in the input layer and produces a sequence of vectors in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3372d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "print(train_data.data.shape)\n",
    "print(train_data.targets.shape)\n",
    "plt.imshow(train_data.data[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e59f417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a521a30af694>:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  test_x = Variable(test_data.data, volatile=True) \\\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data/',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_x = Variable(test_data.data, volatile=True) \\\n",
    "        .type(torch.FloatTensor) / 255\n",
    "test_y = test_data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5adb4",
   "metadata": {},
   "source": [
    "Long Short-Time Memory (LSTM) network is effective for holding memory for a long time. If use `nn.RNN()`, it hardly learns the parameters, because the vanilla implementation of RNN cannot hold or remember the imformation for a long time.\n",
    "\n",
    "The input size is the image width. Hidden size is the number of neurons in the hidden layer. Output size is (Hidden size, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bdc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = INPUT_SIZE,\n",
    "            hidden_size = 64,\n",
    "            num_layers = 1,\n",
    "            batch_first = True      # I/O.shape = (BATCH_SIZE, TIME_STEP, IO_SIZE)\n",
    "        )\n",
    "        self.out = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x.shape = (BATCH_SIZE, TIME_STEP, INPUT_SIZE)\n",
    "        # r_out.shape = (BATCH_SIZE, TIME_STEP, OUTPUT_SIZE)\n",
    "        # h_n.shape = (n_layers, BATCH_SIZE, hidden_size)\n",
    "        # h_c.shape = (n_layers, BATCH_SIZE, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)\n",
    "        \n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ba46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39627218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | step:   0 | train loss = 2.3088 | test accuracy =  960 / 10000\n",
      "Epoch:  0 | step: 100 | train loss = 0.8970 | test accuracy = 7166 / 10000\n",
      "Epoch:  0 | step: 200 | train loss = 0.3180 | test accuracy = 8451 / 10000\n",
      "Epoch:  0 | step: 300 | train loss = 0.3900 | test accuracy = 9137 / 10000\n",
      "Epoch:  0 | step: 400 | train loss = 0.1543 | test accuracy = 9374 / 10000\n",
      "Epoch:  0 | step: 500 | train loss = 0.1907 | test accuracy = 9472 / 10000\n",
      "Epoch:  0 | step: 600 | train loss = 0.1787 | test accuracy = 9437 / 10000\n",
      "Epoch:  0 | step: 700 | train loss = 0.0734 | test accuracy = 9555 / 10000\n",
      "Epoch:  0 | step: 800 | train loss = 0.0559 | test accuracy = 9680 / 10000\n",
      "Epoch:  0 | step: 900 | train loss = 0.1129 | test accuracy = 9660 / 10000\n",
      "Epoch:  0 | train loss = 0.0797 | test accuracy = 9571 / 10000\n",
      "Epoch:  1 | train loss = 0.1031 | test accuracy = 9685 / 10000\n",
      "Epoch:  2 | train loss = 0.1082 | test accuracy = 9778 / 10000\n",
      "Epoch:  3 | train loss = 0.0062 | test accuracy = 9792 / 10000\n",
      "Epoch:  4 | train loss = 0.0090 | test accuracy = 9804 / 10000\n",
      "Epoch:  5 | train loss = 0.0437 | test accuracy = 9773 / 10000\n",
      "Epoch:  6 | train loss = 0.0513 | test accuracy = 9722 / 10000\n",
      "Epoch:  7 | train loss = 0.0468 | test accuracy = 9744 / 10000\n",
      "Epoch:  8 | train loss = 0.0530 | test accuracy = 9801 / 10000\n",
      "Epoch:  9 | train loss = 0.0088 | test accuracy = 9764 / 10000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        # batch_x.shape = (BATCH_SIZE, INPUT_SIZE, INPUT_SIZE)\n",
    "        batch_x = Variable(x.view(-1, 28, 28))\n",
    "        # batch_x.shape = (BATCH_SIZE)\n",
    "        batch_y = Variable(y)\n",
    "        \n",
    "        output = rnn(batch_x)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 0 and  step % 100 == 0:\n",
    "            test_output = rnn(test_x)\n",
    "            test_y_pred = torch.max(test_output, dim=1).indices\n",
    "            accuracy = (test_y_pred == test_y).sum()\n",
    "            print('Epoch: {:2} | step: {:3} | train loss = {:.4f} | test accuracy = {:4} / {}'.\n",
    "                  format(epoch, step, loss.data, accuracy, test_y.shape[0]))\n",
    "    test_output = rnn(test_x)\n",
    "    test_y_pred = torch.max(test_output, dim=1).indices\n",
    "    accuracy = (test_y_pred == test_y).sum()\n",
    "    print('Epoch: {:2} | train loss = {:.4f} | test accuracy = {:4} / {}'.\n",
    "            format(epoch, loss.data, accuracy, test_y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8afa1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n",
      "actually:  tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "test_output = rnn(test_x[:10])\n",
    "test_y_pred = torch.max(test_output, dim=1).indices\n",
    "print(\"predicted:\", test_y_pred)\n",
    "print(\"actually: \", test_y[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
