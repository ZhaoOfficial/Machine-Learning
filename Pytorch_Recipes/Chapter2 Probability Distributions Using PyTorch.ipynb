{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "**Probability Distributions Using PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.distributions as distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-1. Sampling Tensors\n",
    "Weight initialization is an important task in training a neural network and any kind of deep learning model, such as a convolutional neural network (CNN), a deep neural network (DNN), and a recurrent neural network (RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2169,  1.5546, -2.1656, -0.7989],\n",
       "        [ 1.1052, -0.6994,  1.0420,  0.1689],\n",
       "        [ 0.5121,  0.9921, -0.5160, -1.3243],\n",
       "        [ 1.2463,  0.2345,  0.9326, -0.5185]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(20210620)\n",
    "torch.randn(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform distribution\n",
    "$$P(X)=\\begin{cases}\\frac{1}{b-a}&a\\le X\\le b\\\\0&X>a,X<b\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6739, 0.1073, 0.8637, 0.1027],\n",
       "        [0.5573, 0.6963, 0.3788, 0.1305],\n",
       "        [0.5607, 0.7941, 0.4270, 0.4455],\n",
       "        [0.3962, 0.7553, 0.7715, 0.6997]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(4, 4).uniform_(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli distribution\n",
    "$$\\begin{cases}P(X=1)=p\\\\P(X=0)=1-p\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0.]])\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# way 1\n",
    "print(torch.Tensor(4, 4).bernoulli(0.5))\n",
    "# way 2\n",
    "print(torch.bernoulli(torch.Tensor(4, 4).uniform_(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial distribution\n",
    "$$\\mathbf X\\thicksim \\text{Mult}_k(n, \\mathbf p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2, 14,  9])\n",
      "tensor([ 8,  8, 14, 14,  4])\n"
     ]
    }
   ],
   "source": [
    "# without replacement\n",
    "print(torch.multinomial(\n",
    "    torch.Tensor(16).uniform_(0, 1),\n",
    "    num_samples=3\n",
    "))\n",
    "# with replacement\n",
    "print(torch.multinomial(\n",
    "    torch.Tensor(16).uniform_(0, 1),\n",
    "    num_samples=5,\n",
    "    replacement=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal distribution\n",
    "$$X\\thicksim\\mathcal N(\\mu,\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7136,  0.0261,  3.0238,  3.9522,  5.3662,  5.7489,  6.8118,  7.5106,\n",
      "         8.8585,  9.9411])\n",
      "tensor([ 0.5567, -2.2587,  1.3832,  2.8100,  8.0504])\n",
      "tensor([-0.8894, -1.0986, -1.6995, -1.2653,  1.5386, -0.4245,  0.2302,  1.8631,\n",
      "        -0.4695,  0.9538])\n"
     ]
    }
   ],
   "source": [
    "# each element is in distribution of N(mean, std^2)\n",
    "print(torch.normal(\n",
    "    mean=torch.linspace(1, 10, 10),\n",
    "    std=torch.linspace(1, 0.1, 10)\n",
    "))\n",
    "\n",
    "print(torch.normal(\n",
    "    mean=0.5,\n",
    "    std=torch.linspace(1, 5, 5)\n",
    "))\n",
    "\n",
    "print(torch.normal(\n",
    "    mean=-0.5, std=1.0, size=(10,)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-2. Variable Tensors\n",
    "What is a variable in PyTorch and how is it defined? What is a random variable in PyTorch?\n",
    "\n",
    "**Computational Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 10\n",
    "col = 15\n",
    "# using autograd module to create a varible\n",
    "x1 = Variable(torch.randn(row, col), \n",
    "              requires_grad=True)\n",
    "x2 = Variable(torch.randn(row, col), \n",
    "              requires_grad=True)\n",
    "x3 = Variable(torch.randn(row, col), \n",
    "              requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.3499, grad_fn=<SumBackward0>)\n",
      "tensor(-10.3499, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.sum(x1 * x2 * x3)\n",
    "print(a)\n",
    "a.backward()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-3. Basic Statistics Problem\n",
    "How do we compute basic statistics, such as mean, median, mode, and so forth, from a Torch tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4291)\n",
      "tensor([-0.7599,  1.1393,  1.9067, -0.4588,  0.3184])\n",
      "tensor([0.8684, 0.2926, 0.4962, 0.0594])\n"
     ]
    }
   ],
   "source": [
    "n = torch.normal(mean=1, std=2, size=(4, 5))\n",
    "# mean\n",
    "print(torch.mean(n))\n",
    "# mean of axis 0 (or dim=0)\n",
    "print(torch.mean(n, axis=0))\n",
    "# mean of axis 1 (or dim=1)\n",
    "print(torch.mean(n, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.mode(\n",
      "values=tensor([-1.7531, -3.4031, -0.0736, -2.2050]),\n",
      "indices=tensor([0, 4, 4, 0]))\n",
      "tensor(0.2540)\n",
      "tensor(1.9757)\n",
      "tensor(3.9035)\n"
     ]
    }
   ],
   "source": [
    "# mode, default axis=-1\n",
    "print(torch.mode(n))\n",
    "# the same for median, std, var...\n",
    "print(torch.median(n))\n",
    "print(torch.std(n))\n",
    "print(torch.var(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-4. Gradient Computation Problem\n",
    "How do we compute basic gradients from the sample tensors?\n",
    "\n",
    "**Actually, it is the first neuron netword done by me independently.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = torch.tensor([[11.0, 22.0, 33.0]]).T\n",
    "# output\n",
    "y = torch.tensor([[21.0, 14.0, 64.0, 72.0]]).T\n",
    "# weights\n",
    "w = Variable(torch.randn(y.shape[0], x.shape[0]), requires_grad=True)\n",
    "# bias\n",
    "b = Variable(torch.randn(y.shape[0], 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = \n",
      "tensor([[-0.7932,  0.4884,  0.6597],\n",
      "        [ 0.9782, -0.1713,  0.2143],\n",
      "        [ 1.2128,  1.2078,  0.7503],\n",
      "        [ 0.6340,  0.9193,  1.3641]])\n",
      "b = \n",
      "tensor([[-2.7905],\n",
      "        [-0.0658],\n",
      "        [-0.6719],\n",
      "        [-0.2135]])\n",
      "w * x + b = \n",
      "tensor([[21.0000],\n",
      "        [14.0000],\n",
      "        [64.0000],\n",
      "        [72.0000]])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learing_rate = 0.001\n",
    "for epoch in range(epochs):\n",
    "    # forwarding\n",
    "    y_pred = torch.matmul(w, x) + b\n",
    "    # calculating loss\n",
    "    loss_val = torch.nn.functional.mse_loss(y_pred, y)\n",
    "    # backwarding\n",
    "    loss_val.backward()\n",
    "    # gradient descent\n",
    "    w.data = w.data - learing_rate * w.grad.data\n",
    "    # set the gradient to 0 after updating weights\n",
    "    w.grad.data.zero_()\n",
    "# check result\n",
    "print(\"w = \", w.data, sep='\\n')\n",
    "print(\"b = \", b.data, sep='\\n')\n",
    "print(\"w * x + b = \", (torch.matmul(w, x) + b).data, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-5. Tensor Operations\n",
    "How do we compute or perform operations based on variables such as matrix multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor(4, 4).uniform_(-4, 5))\n",
    "y = Variable(torch.Tensor(4, 4).uniform_(0, 1))\n",
    "z = torch.mm(x, y)\n",
    "# some featurs\n",
    "print(z.shape)\n",
    "print(z.requires_grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-6. Tensor Operations\n",
    "How do we compute or perform operations based on variables such as matrix-vector computation, and matrix-matrix and vector-vector calculation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.0659, 10.0311, 10.4802, 10.9511],\n",
      "        [10.2063, 10.4168, 10.7995, 10.2437],\n",
      "        [10.9632, 10.6569, 10.8092, 10.1809],\n",
      "        [10.7521, 10.4165, 10.8021, 10.2873]])\n",
      "tensor([[0.6744, 0.5480, 1.2231, 1.5265],\n",
      "        [0.8148, 0.9337, 1.5424, 0.8191],\n",
      "        [1.5717, 1.1737, 1.5521, 0.7564],\n",
      "        [1.3606, 0.9334, 1.5449, 0.8628]])\n",
      "tensor([[0.0043, 0.0010, 0.2306, 0.9045],\n",
      "        [0.0426, 0.1738, 0.6392, 0.0594],\n",
      "        [0.9278, 0.4315, 0.6548, 0.0327],\n",
      "        [0.5656, 0.1735, 0.6433, 0.0826]])\n",
      "tensor([[1.2316, 0.9109, 1.4944, 0.5181],\n",
      "        [0.6588, 0.5922, 1.0882, 0.6472],\n",
      "        [0.8588, 0.6898, 1.1993, 0.5359],\n",
      "        [1.1917, 0.9253, 1.5775, 0.5027],\n",
      "        [1.0030, 0.8662, 1.5930, 0.7474]])\n"
     ]
    }
   ],
   "source": [
    "mat1 = torch.Tensor(4, 4).uniform_(0, 1)\n",
    "mat2 = torch.Tensor(5, 4).uniform_(0, 1)\n",
    "vec1 = torch.Tensor(4).uniform_(0, 1)\n",
    "print(mat1 + 10)\n",
    "print(mat1 + vec1)\n",
    "print(mat1 * mat1)\n",
    "print(mat2 @ mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2-7. Tensor Operations\n",
    "How do we know which distributions to\n",
    "use and when to use them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4026])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B(0.5, 0.5)\n",
    "d = distributions.beta.Beta(\n",
    "    torch.tensor([0.5]), torch.tensor([0.5])\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  24.,  83., 100.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi_k(0, 0.2, 0.8, 1.0)\n",
    "d = distributions.binomial.Binomial(\n",
    "    100, torch.tensor([0, 0.2, 0.8, 1.0])\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# event probability\n",
    "d = distributions.categorical.Categorical(\n",
    "    torch.tensor([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.0169])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L(10, 0.99)\n",
    "d = distributions.laplace.Laplace(\n",
    "    torch.tensor([10.0]), torch.tensor([0.99])\n",
    ")\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([114.9374])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N(100, 10)\n",
    "d = distributions.normal.Normal(\n",
    "    torch.tensor([100.0]), torch.tensor([10.0])\n",
    ")\n",
    "d.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
